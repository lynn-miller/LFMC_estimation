{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "progressive-angel",
   "metadata": {},
   "source": [
    "# Main Result\n",
    "Generates the figure and computes the evaluation metrics for the main result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dac64e-43f4-495f-a2a0-1b107022f2de",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "\n",
    "import initialise\n",
    "import common\n",
    "from analysis_utils import calc_statistics, plot_results\n",
    "from display_utils import truncate_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS = ['out-of-site', 'within-site']\n",
    "samples_file = os.path.join(common.DATASETS_DIR, 'samples_365days.csv')\n",
    "model_dir1 = os.path.join(common.MODELS_DIR, f'{SCENARIOS[0]}_models')\n",
    "model_dir2 = os.path.join(common.MODELS_DIR, f'{SCENARIOS[1]}_models')\n",
    "holdout_file = os.path.join('data', 'holdout_index.csv')\n",
    "design_file = os.path.join('data', 'design_index.csv')\n",
    "output_dir = common.FIGURES_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = common.ANALYSIS_MODEL\n",
    "ensemble_size = common.ENSEMBLE_SIZE\n",
    "ensemble_runs = common.ENSEMBLE_RUNS\n",
    "precision = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45cfeab-61ff-4cde-b311-d8102a93c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_dir2, 'model_params.json'), 'r') as f:\n",
    "    ws_params = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-junior",
   "metadata": {},
   "source": [
    "## Get the samples and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e18d81-212f-42de-b3d3-88fb3ebdcef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples1 = pd.read_csv(samples_file, index_col=0)\n",
    "predict1 = pd.read_csv(os.path.join(model_dir1, f'ensemble{ensemble_size}_{model}.csv'), index_col=0).reindex(samples1.index)\n",
    "\n",
    "predict2 = pd.read_csv(os.path.join(model_dir2, f'ensemble{ensemble_size}_{model}.csv'), index_col=0)\n",
    "samples2 = samples1.reindex(predict2.index)\n",
    "\n",
    "holdout_samples = pd.read_csv(holdout_file, index_col=0)\n",
    "design_samples = pd.read_csv(design_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2749c-0d5a-4039-82b9-fa547c90a18a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats1 = pd.read_csv(os.path.join(model_dir1, f'ensemble{ensemble_size}_stats.csv'), index_col=(0,1)).loc[model].T\n",
    "means1 = stats1.mean()\n",
    "stats2 =  pd.read_csv(os.path.join(model_dir2, f'ensemble{ensemble_size}_stats.csv'), index_col=(0,1)).loc[model].T\n",
    "means2 = stats2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-commissioner",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60927729-0c07-447e-8d28-4d1c14173e1b",
   "metadata": {},
   "source": [
    "Generate scatter plots of the estimated versus measured LFMC using the first ensemble only. The statistic in the figure are the means of all 50 ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad81c9-d89f-443f-a35c-9bdee3c10a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_size = 8\n",
    "vmax1 = 40\n",
    "vmax2 = 16\n",
    "vmin = 1\n",
    "plt.rcParams.update({'font.size': font_size})\n",
    "fig = plt.figure(constrained_layout=False, figsize=(8.617, 2.87), dpi=500, linewidth=2, edgecolor=\"black\")\n",
    "gspec = fig.add_gridspec(ncols=2, nrows=1)\n",
    "cmap = truncate_colormap(plt.get_cmap('Greens'), minval=0.3, maxval=1.0, n=-1)\n",
    "\n",
    "plot = fig.add_subplot(gspec[0, 0])\n",
    "plot_results(f'(a) {SCENARIOS[1].capitalize()} Models', samples2['LFMC value'], predict2['0'],\n",
    "             top_text=means2, bottom_text=f'{predict2.shape[0]:,} samples',\n",
    "             lower=0, upper=400, diagonal=True, regress='black',\n",
    "             ax=plot, cmap=cmap, vmin=vmin, vmax=vmax2)\n",
    "plot.set_yticks(range(0, 500, 100))\n",
    "cbar2 = fig.colorbar(cm.ScalarMappable(norm=Normalize(vmin=vmin, vmax=vmax2), cmap=cmap), ax=plot, aspect=20)\n",
    "cbar2.ax.set_title('Counts', y=1.01)\n",
    "cbar2.set_ticks(range(2, 18, 2))\n",
    "\n",
    "plot = fig.add_subplot(gspec[0, 1])\n",
    "plot_results(f'(b) {SCENARIOS[0].capitalize()} Models', samples1['LFMC value'], predict1['0'],\n",
    "             top_text=means1, bottom_text=f'{predict1.shape[0]:,} samples',\n",
    "             lower=0, upper=400, diagonal=True, regress='black',\n",
    "             ax=plot, cmap=cmap, vmin=vmin, vmax=vmax1)\n",
    "plot.set_yticks(range(0, 500, 100))\n",
    "cbar1 = fig.colorbar(cm.ScalarMappable(norm=Normalize(vmin=vmin, vmax=vmax1), cmap=cmap), ax=plot, aspect=20)\n",
    "cbar1.ax.set_title('Counts', y=1.01)\n",
    "cbar1.set_ticks(range(5, 45, 5))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "fig.savefig(os.path.join(output_dir, 'Main result.jpeg'), format=\"jpeg\", bbox_inches='tight', pad_inches=0.2, dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b55922-ee9c-42f2-94f6-ed3d67600082",
   "metadata": {},
   "source": [
    "## Main Result - Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02546d6d-3703-44fc-adcf-f67cba04d057",
   "metadata": {},
   "source": [
    "### Within-Site Models\n",
    "Calculate and display all metrics for the within-site models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0f87b-0659-4a0d-889f-941536acd82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_samples2 = samples2.loc[design_samples.index.intersection(samples2.index)]\n",
    "design_predict = predict2.loc[design_samples2.index]\n",
    "design_stats = pd.DataFrame([calc_statistics(design_samples2['LFMC value'], pred_[1]) for pred_ in design_predict.iteritems()])\n",
    "\n",
    "holdout_samples2 = samples2.loc[holdout_samples.index.intersection(samples2.index)]\n",
    "holdout_predict = predict2.loc[holdout_samples2.index]\n",
    "holdout_stats = pd.DataFrame([calc_statistics(holdout_samples2['LFMC value'], pred_[1]) for pred_ in holdout_predict.iteritems()])\n",
    "\n",
    "years = [y for y in range(ws_params['splitYear'], ws_params['splitYear'] + ws_params['splitFolds'])]\n",
    "stats = [stats2]\n",
    "counts = [predict2.shape[0]]\n",
    "for year in years:\n",
    "    year_preds = predict2[samples2[ws_params['yearColumn']] == year]\n",
    "    counts.append(year_preds.shape[0])\n",
    "    stats_ = pd.DataFrame([calc_statistics(samples2['LFMC value'][year_preds.index], pred_[1]) for pred_ in year_preds.iteritems()])\n",
    "    stats.append(stats_)\n",
    "\n",
    "counts.extend([design_predict.shape[0], holdout_predict.shape[0]])\n",
    "stats.extend([design_stats, holdout_stats])\n",
    "means = [stats_.mean() for stats_ in stats]\n",
    "stds = [stats_.std() for stats_ in stats]\n",
    "\n",
    "group_names = ['All samples'] + years + ['Design samples', 'Held out samples']\n",
    "means = pd.concat(means, keys=group_names).unstack()\n",
    "stds = pd.concat(stds, keys=group_names).unstack()\n",
    "counts = pd.Series(counts, index=group_names)\n",
    "df_list = [counts, means.RMSE, stds.RMSE, means.Bias, stds.Bias, means.R2, stds.R2]\n",
    "pd.concat(df_list, axis=1).set_axis(['Samples', 'RMSE-mean', 'RMSE-std', 'Bias-mean', 'Bias-std', 'R2-mean', 'R2-std'], axis=1).round(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14a182-fd36-4918-8953-9026c6371616",
   "metadata": {},
   "source": [
    "### Out of Site Models\n",
    "Calculate and display all metrics for the out-of-site models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4272de-528b-48ee-b1d4-e74816d02567",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_samples1 = samples1.loc[design_samples.index.intersection(samples1.index)]\n",
    "design_predict = predict1.loc[design_samples.index]\n",
    "design_stats = pd.DataFrame([calc_statistics(design_samples1['LFMC value'], pred_[1]) for pred_ in design_predict.iteritems()])\n",
    "\n",
    "holdout_samples1 = samples1.loc[holdout_samples.index.intersection(samples1.index)]\n",
    "holdout_predict = predict1.loc[holdout_samples.index]\n",
    "holdout_stats = pd.DataFrame([calc_statistics(holdout_samples1['LFMC value'], pred_[1]) for pred_ in holdout_predict.iteritems()])\n",
    "\n",
    "group_names = ['All samples', 'Design samples', 'Held out samples']\n",
    "means = pd.concat([means1, design_stats.mean(), holdout_stats.mean()], keys=group_names).unstack()\n",
    "stds = pd.concat([stats1.std(), design_stats.std(), holdout_stats.std()], keys=group_names).unstack()\n",
    "counts = pd.Series([predict1.shape[0], design_predict.shape[0], holdout_predict.shape[0]], index=group_names)\n",
    "df_list = [counts, means.RMSE, stds.RMSE, means.Bias, stds.Bias, means.R2, stds.R2]\n",
    "pd.concat(df_list, axis=1).set_axis(['Samples', 'RMSE-mean', 'RMSE-std', 'Bias-mean', 'Bias-std', 'R2-mean', 'R2-std'], axis=1).round(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8431c99-5e5e-4bb5-b94d-e001745dc91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFMC",
   "language": "python",
   "name": "lfmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
