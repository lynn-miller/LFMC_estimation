{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b331f671-44ca-47cf-bdc9-1b666d443fbf",
   "metadata": {},
   "source": [
    "# Create Ensembles for Main Models\n",
    "- Generates ensembles for both the within-site and out-of-site models\n",
    "- Ensemble sizes are 5, 10, 15, 20, and 25\n",
    "- 50 ensembles of each size are created by sampling (without replacement) from the pool of models\n",
    "- Save the ensemble predictions and statistics\n",
    "- Equivalent prediction and statistics files for the single models are also created\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "import initialise\n",
    "import common\n",
    "from results_utils import generate_ensembles\n",
    "from analysis_utils import samples_with_historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49a7b5-6bf8-4425-8d8f-e83599875850",
   "metadata": {},
   "source": [
    "## Directories and other settings\n",
    "- Update the model directories as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = os.path.join(common.DATASETS_DIR, 'samples_365days.csv')\n",
    "model_dirs = [\n",
    "    os.path.join(common.MODELS_DIR, 'out-of-site_models'),\n",
    "    os.path.join(common.MODELS_DIR, 'within-site_models')\n",
    "]\n",
    "model_names = ['Out-of-site', 'Within-site']\n",
    "\n",
    "precision = 3       # floating point precision for saved predictions\n",
    "random_seed = 9876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436b7219-64fc-4e0e-88e6-d100b4561915",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_dirs[1], 'model_params.json'), 'r') as f:\n",
    "    model_params = json.load(f)\n",
    "samples1 = pd.read_csv(samples_file, index_col=0)\n",
    "temp_predict = pd.read_csv(os.path.join(model_dirs[1], 'run0', 'predictions.csv'), index_col=0)\n",
    "samples2, _ = samples_with_historical_data(samples1, temp_predict, model_params['siteColumn'], model_params['yearColumn'])\n",
    "samples_index = [samples1.index, samples2.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-infrastructure",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate the ensembles and save predictions\n",
    "Generate ensembles of various sizes for each of the models. For each ensemble size, randomly select the runs to ensemble, then create the ensembles. This is repeated for the desired number of ensembles of each size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f7f3fc-f05c-4404-80ad-e90627608e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, model_dir in enumerate(model_dirs):\n",
    "    print(f\"Processing {model_names[m]} models; model directory {model_dir}\")\n",
    "    model_predicts = []\n",
    "    for run_dir in glob.glob(os.path.join(model_dir, 'run*')):\n",
    "        model_predicts.append(pd.read_csv(os.path.join(run_dir, 'predictions.csv'), index_col=0).loc[samples_index[m]])\n",
    "\n",
    "    predict, all_stats = generate_ensembles(model_predicts, common.ENSEMBLE_RUNS, common.ENSEMBLE_SIZES, random_seed=random_seed)\n",
    "\n",
    "    print(\"Saving ensembles ...\")\n",
    "    for num, ens_name in enumerate(common.ENSEMBLE_NAMES):\n",
    "        if num == 0:\n",
    "            file_name = f\"single_{common.ANALYSIS_MODEL}.csv\"\n",
    "            stats_fname = f\"single_stats.csv\"\n",
    "        else:\n",
    "            file_name = f\"ensemble{common.ENSEMBLE_SIZES[num]:02}_{common.ANALYSIS_MODEL}.csv\"\n",
    "            stats_fname = f\"ensemble{common.ENSEMBLE_SIZES[num]:02}_stats.csv\"\n",
    "        print(f\"   {ens_name}; predictions: {file_name}, stats: {stats_fname}\")\n",
    "        df = pd.concat([pred_[common.ANALYSIS_MODEL] for pred_ in predict[num]], axis=1, ignore_index=True).round(precision)\n",
    "        df.to_csv(os.path.join(model_dir, file_name))\n",
    "        df = pd.DataFrame([run.stack() for run in all_stats[num]]).T\n",
    "        df.to_csv(os.path.join(model_dir, stats_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566500e-9900-48c1-83e7-018fb3f10eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFMC",
   "language": "python",
   "name": "lfmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
