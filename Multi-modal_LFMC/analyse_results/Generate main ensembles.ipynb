{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b331f671-44ca-47cf-bdc9-1b666d443fbf",
   "metadata": {},
   "source": [
    "# Create Ensembles for Main Models\n",
    "- Generates ensembles for both the within-site and out-of-site models\n",
    "- Ensemble sizes are 5, 10, 15, 20, and 25\n",
    "- 50 ensembles of each size are created by sampling (without replacement) from the pool of models\n",
    "- Save the ensemble predictions and statistics\n",
    "- Equivalent prediction and statistics files for the single models are also created\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ignored-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "import initialise\n",
    "import common\n",
    "from model_utils import generate_ensembles\n",
    "from analysis_utils import samples_with_historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49a7b5-6bf8-4425-8d8f-e83599875850",
   "metadata": {},
   "source": [
    "## Directories and other settings\n",
    "- Update the model directories as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "african-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = os.path.join(common.DATASETS_DIR, 'samples_365days.csv')\n",
    "model_dirs = [\n",
    "    os.path.join(common.MODELS_DIR, 'out-of-site_models'),\n",
    "    os.path.join(common.MODELS_DIR, 'within-site_models')\n",
    "]\n",
    "model_names = ['Out-of-site', 'Within-site']\n",
    "\n",
    "precision = 3       # floating point precision for saved predictions\n",
    "random_seed = 9876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436b7219-64fc-4e0e-88e6-d100b4561915",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_dirs[1], 'model_params.json'), 'r') as f:\n",
    "    model_params = json.load(f)\n",
    "samples1 = pd.read_csv(samples_file, index_col=0)\n",
    "temp_predict = pd.read_csv(os.path.join(model_dirs[1], 'run0', 'predictions.csv'), index_col=0)\n",
    "samples2, _ = samples_with_historical_data(samples1, temp_predict, model_params['siteColumn'], model_params['yearColumn'])\n",
    "samples_index = [samples1.index, samples2.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-infrastructure",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate the ensembles and save predictions\n",
    "Generate ensembles of various sizes for each of the models. For each ensemble size, randomly select the runs to ensemble, then create the ensembles. This is repeated for the desired number of ensembles of each size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f7f3fc-f05c-4404-80ad-e90627608e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Out-of-site models; model directory G:\\My Drive\\LFMC Data\\multi_modal_LFMC\\Models\\out-of-site_models\n",
      "Generating ensembles - size 1: \n",
      "Generating ensembles - size 5: .........10.........20.........30.........40.........50\n",
      "Generating ensembles - size 10: .........10.........20.........30.........40.........50\n",
      "Generating ensembles - size 15: .........10.........20.........30.........40.........50\n",
      "Generating ensembles - size 20: .........10.........20.........30.........40.........50\n",
      "Generating ensembles - size 25: .........10.........20.........30.........40.........50\n",
      "Saving ensembles ...\n",
      "   Single model; predictions: single_base.csv, stats: single_stats.csv\n",
      "   Ensemble 5; predictions: ensemble05_base.csv, stats: ensemble05_stats.csv\n",
      "   Ensemble 10; predictions: ensemble10_base.csv, stats: ensemble10_stats.csv\n",
      "   Ensemble 15; predictions: ensemble15_base.csv, stats: ensemble15_stats.csv\n",
      "   Ensemble 20; predictions: ensemble20_base.csv, stats: ensemble20_stats.csv\n",
      "   Ensemble 25; predictions: ensemble25_base.csv, stats: ensemble25_stats.csv\n",
      "Processing Within-site models; model directory G:\\My Drive\\LFMC Data\\multi_modal_LFMC\\Models\\within-site_models\n",
      "Generating ensembles - size 1: \n",
      "Generating ensembles - size 5: .........10.........20.........30.........40.........50\n",
      "Generating ensembles - size 10: .........10.........20.........30.........40.........50\n",
      "Generating ensembles - size 15: .........10.........20.........30.........40.........50\n",
      "Generating ensembles - size 20: .........10.........20.........30.........40.........50\n",
      "Generating ensembles - size 25: .........10.........20.........30.........40.........50\n",
      "Saving ensembles ...\n",
      "   Single model; predictions: single_base.csv, stats: single_stats.csv\n",
      "   Ensemble 5; predictions: ensemble05_base.csv, stats: ensemble05_stats.csv\n",
      "   Ensemble 10; predictions: ensemble10_base.csv, stats: ensemble10_stats.csv\n",
      "   Ensemble 15; predictions: ensemble15_base.csv, stats: ensemble15_stats.csv\n",
      "   Ensemble 20; predictions: ensemble20_base.csv, stats: ensemble20_stats.csv\n",
      "   Ensemble 25; predictions: ensemble25_base.csv, stats: ensemble25_stats.csv\n"
     ]
    }
   ],
   "source": [
    "for m, model_dir in enumerate(model_dirs):\n",
    "    print(f\"Processing {model_names[m]} models; model directory {model_dir}\")\n",
    "    model_predicts = []\n",
    "    for run_dir in glob.glob(os.path.join(model_dir, 'run*')):\n",
    "        model_predicts.append(pd.read_csv(os.path.join(run_dir, 'predictions.csv'), index_col=0).loc[samples_index[m]])\n",
    "\n",
    "    predict, all_stats = generate_ensembles(model_predicts, common.ENSEMBLE_RUNS, common.ENSEMBLE_SIZES, random_seed=random_seed)\n",
    "\n",
    "    print(\"Saving ensembles ...\")\n",
    "    for num, ens_name in enumerate(common.ENSEMBLE_NAMES):\n",
    "        if num == 0:\n",
    "            file_name = f\"single_{common.ANALYSIS_MODEL}.csv\"\n",
    "            stats_fname = f\"single_stats.csv\"\n",
    "        else:\n",
    "            file_name = f\"ensemble{common.ENSEMBLE_SIZES[num]:02}_{common.ANALYSIS_MODEL}.csv\"\n",
    "            stats_fname = f\"ensemble{common.ENSEMBLE_SIZES[num]:02}_stats.csv\"\n",
    "        print(f\"   {ens_name}; predictions: {file_name}, stats: {stats_fname}\")\n",
    "        df = pd.concat([pred_[common.ANALYSIS_MODEL] for pred_ in predict[num]], axis=1, ignore_index=True).round(precision)\n",
    "        df.to_csv(os.path.join(model_dir, file_name))\n",
    "        df = pd.DataFrame([run.stack() for run in all_stats[num]]).T\n",
    "        df.to_csv(os.path.join(model_dir, stats_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566500e-9900-48c1-83e7-018fb3f10eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFMC",
   "language": "python",
   "name": "lfmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
