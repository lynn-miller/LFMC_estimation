{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed595e42-4a77-4afc-8341-fc619e93ba22",
   "metadata": {},
   "source": [
    "# Create Ensembles for Ablations and Omit-One tests\n",
    "- Generates ensembles for both the within-site and out-of-site models\n",
    "- Ensemble size is 20\n",
    "- 50 ensembles are created by sampling (without replacement) from the pool of models\n",
    "- Save the ensemble predictions and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4ce86-4017-4e7d-b46a-560c68ca84bb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import initialise\n",
    "import common\n",
    "from model_utils import generate_ensembles\n",
    "from analysis_utils import samples_with_historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49a7b5-6bf8-4425-8d8f-e83599875850",
   "metadata": {},
   "source": [
    "## Directories and other settings\n",
    "- Update the model directories as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dacc714-5848-4666-983f-255e8e98cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = os.path.join(common.DATASETS_DIR, 'samples_365days.csv')\n",
    "model_dirs = [\n",
    "    os.path.join(common.MODELS_DIR, 'out-of-site_ablation'),\n",
    "    os.path.join(common.MODELS_DIR, 'within-site_ablation'),\n",
    "    os.path.join(common.MODELS_DIR, 'out-of-site_omit_one'),\n",
    "    os.path.join(common.MODELS_DIR, 'within-site_omit_one'),\n",
    "]\n",
    "\n",
    "precision = 3       # floating point precision for saved predictions\n",
    "random_seed = 9876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b3f404-ede5-40b0-bf17-cbb50d74a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_dirs[1], 'model_params.json'), 'r') as f:\n",
    "    model_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74039f18-076f-4024-822e-f466fac1aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples1 = pd.read_csv(samples_file, index_col=0)\n",
    "predict1 = pd.read_csv(os.path.join(model_dirs[2], 'test0', 'run0', 'predictions.csv'), index_col=0).reindex(samples1.index)\n",
    "temp_predict = pd.read_csv(os.path.join(model_dirs[1], 'test0', 'run0', 'predictions.csv'), index_col=0)\n",
    "samples2, _ = samples_with_historical_data(samples1, temp_predict, model_params['siteColumn'], model_params['yearColumn'])\n",
    "samples_index = [samples1.index, samples2.index, samples1.index, samples2.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-infrastructure",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read Test Predictions\n",
    "Read the prediction files for each test and retain the predictions that match the samples index. Either calculate the prediction statistics or read from the saved stats file (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ed3f4-8c17-4fdb-90fa-40a5e29e1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_predictions(model_dir, samples_index):\n",
    "    model_predicts = []\n",
    "    test_dirs = sorted(glob.glob(os.path.join(model_dir, f'test*')))\n",
    "    for test_dir in test_dirs:\n",
    "        test_predicts = []\n",
    "        for run_dir in glob.glob(os.path.join(test_dir, 'run*')):\n",
    "            preds_ = pd.read_csv(os.path.join(run_dir, 'predictions.csv'), index_col=0).loc[samples_index]\n",
    "            test_predicts.append(preds_)\n",
    "        model_predicts.append(test_predicts)\n",
    "    return model_predicts, test_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded852b-c065-4a16-8045-2ed00fda1aa8",
   "metadata": {},
   "source": [
    "### Save Ensemble Predictions\n",
    "Save the predictions made by the ensembles using the model of interest. Each size ensemble is stored in a separate CSV file. Columns are the individual ensemble predictions and rows are the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e0c8d-f762-42b4-9ae9-acc66bac56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ensembles(test_dirs, model_predicts, model_stats, precision):\n",
    "    for num in range(len(model_predicts)):\n",
    "        file_name = f\"ensemble{common.ENSEMBLE_SIZE}_{common.ANALYSIS_MODEL}.csv\"\n",
    "        stats_fname = f\"ensemble{common.ENSEMBLE_SIZE}_stats.csv\"\n",
    "        test_dir = os.path.join(model_dir, f'test{num}')\n",
    "        test_dir = test_dirs[num]\n",
    "        print(os.path.join(test_dir, file_name))\n",
    "        print(os.path.join(test_dir, stats_fname))\n",
    "        df = pd.concat([pred_[common.ANALYSIS_MODEL] for pred_ in model_predicts[num]], axis=1, ignore_index=True).round(precision)\n",
    "        df.to_csv(os.path.join(test_dir, file_name))\n",
    "        df = pd.DataFrame([run.stack() for run in model_stats[num]]).T\n",
    "        df.to_csv(os.path.join(test_dir, stats_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d75fc6-8554-456b-abb9-064651782994",
   "metadata": {},
   "source": [
    "### Generate the ensembles\n",
    "Generate ensembles of various sizes for each of the models. For each ensemble size, randomly select the runs to ensemble, then create the ensembles. This is repeated for the desired number of ensembles of each size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef1671-96c3-4ece-afb0-ed631a6c92d1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for test_num, model_dir in enumerate(model_dirs):\n",
    "    print(f'Processing experiment {test_num}: {model_dir}')\n",
    "    model_predicts, test_dirs = read_predictions(model_dir, samples_index[test_num])\n",
    "    predict, all_stats = generate_ensembles(model_predicts, common.ENSEMBLE_RUNS, common.ENSEMBLE_SIZE, random_seed=random_seed)\n",
    "    write_ensembles(test_dirs, predict, all_stats, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677223d8-e163-4236-8feb-a0331d15bac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFMC",
   "language": "python",
   "name": "lfmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
