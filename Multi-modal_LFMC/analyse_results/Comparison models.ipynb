{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adb59277-2b10-47ac-b31c-729b73cac0e2",
   "metadata": {},
   "source": [
    "# Model Comparisons\n",
    "Compute the evaluation metrics and generate the figure for the model comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56447f0d-9964-4c35-b840-916d6a4f91d9",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import initialise\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29215b63-da0d-4ef4-9bf8-840a974c14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = os.path.join(common.DATASETS_DIR, 'samples_365days.csv')\n",
    "model_dir = os.path.join(common.MODELS_DIR, 'comparison_models')\n",
    "with open(os.path.join(model_dir, 'model_params.json'), 'r') as f:\n",
    "    model_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = common.ANALYSIS_MODEL\n",
    "ensemble_size = common.ENSEMBLE_SIZE\n",
    "ensemble_runs = common.ENSEMBLE_RUNS\n",
    "single_model = common.MODIS_TEMPCNN_MODEL\n",
    "runs = common.EVALUATION_RUNS\n",
    "precision = 2\n",
    "tests = ['Multi-tempCNN:within-site architecture*', 'Multi-tempCNN:out-of-site architecture*',\n",
    "         'Within-site scenario:out-of-site architecture', 'Out-of-site scenario:within-site architecture',\n",
    "         'Within-site scenario:Modis-tempCNN', 'Out-of-site scenario:Modis-tempCNN',]\n",
    "num_tests = len(tests)\n",
    "\n",
    "# The ensembled results are needed for the Multi-tempCNN comparisons (tests 0 & 1)\n",
    "ensemble_range = range(2)\n",
    "# The single models for the Modis-tempCNN comparisons (tests 2 & 3)  \n",
    "single_range = range(2, 4)\n",
    "\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3a3ece-097c-40ed-af50-1549b60fa34f",
   "metadata": {},
   "source": [
    "## Load Model Predictions and Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce747a67-e68a-4df3-9dfe-ba44510ecfc9",
   "metadata": {},
   "source": [
    "### Multi-tempCNN ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399eaf4f-4b0e-4383-a017-bfc6a342eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predict = []\n",
    "all_stats = []\n",
    "for dir_ in sorted(glob.glob(os.path.join(common.MODELS_DIR, '*site_models')), reverse=True):\n",
    "    file_name = f\"ensemble{ensemble_size}_{ensemble_model}.csv\"\n",
    "    stats_fname = f\"ensemble{ensemble_size}_stats.csv\"\n",
    "    all_predict.append(pd.read_csv(os.path.join(dir_, file_name), index_col=0))\n",
    "    all_stats.append(pd.read_csv(os.path.join(dir_, stats_fname), index_col=(0,1)).loc[ensemble_model].T)\n",
    "for num in ensemble_range:\n",
    "    test_name = f'test{num}'\n",
    "    file_name = f\"ensemble{ensemble_size}_{ensemble_model}.csv\"\n",
    "    stats_fname = f\"ensemble{ensemble_size}_stats.csv\"\n",
    "    all_predict.append(pd.read_csv(os.path.join(model_dir, test_name, file_name), index_col=0))\n",
    "    all_stats.append(pd.read_csv(os.path.join(model_dir, test_name, stats_fname), index_col=(0,1)).loc[ensemble_model].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39778d5d-b31f-4ca8-9945-27861686e60d",
   "metadata": {},
   "source": [
    "### Modis-tempCNN single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f108c-93fc-4254-9977-46f66279c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in single_range:\n",
    "    file_name = f\"predictions_{single_model}.csv\"\n",
    "    test_name = f'test{num}'\n",
    "    all_predict.append(pd.read_csv(os.path.join(model_dir, test_name, file_name), index_col=0))\n",
    "    all_stats.append(pd.read_csv(os.path.join(model_dir, f'test{num}', 'predictions_stats.csv'), index_col=(0,1)).loc[single_model].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d54c0-ce33-4dbb-abe9-6fa854cac818",
   "metadata": {},
   "source": [
    "### Samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f71cf7-9661-447b-80c2-9b2161eae48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = pd.read_csv(samples_file, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8d813-0862-4ae0-9f32-e7cc3303f8be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9628cbd-0c4a-4a94-97c9-9f5546d79883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_results(names, predict_stats, predict_counts, precision):\n",
    "    means = pd.concat([stats_.mean() for stats_ in predict_stats], keys=names).unstack()\n",
    "    stds = pd.concat([stats_.std() for stats_ in predict_stats], keys=names).unstack()\n",
    "    counts = pd.Series(predict_counts, index=names)\n",
    "    df_list = [counts, means.RMSE, stds.RMSE, means.ubRMSE, stds.ubRMSE, means.Bias, stds.Bias, means.R2, stds.R2]\n",
    "    columns = ['Samples', 'RMSE-mean', 'RMSE-std', 'ubRMSE-mean', 'ubRMSE-std', 'Bias-mean', 'Bias-std', 'R2-mean', 'R2-std']\n",
    "    return pd.concat(df_list, axis=1).set_axis(columns, axis=1).round(precision)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cce820-b46e-4dc1-bd23-23cb5c145afa",
   "metadata": {},
   "source": [
    "### Main Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57575ebe-73c1-4f75-8024-f27c8b843f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_list = [pred_.shape[0] for pred_ in all_predict]\n",
    "gen_results(tests, all_stats, counts_list, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935509b-013f-4d14-9e3d-1867834be596",
   "metadata": {},
   "source": [
    "### Generate the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a5662-1779-4bd4-bd5e-1bb69f8f1305",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = ['Multi-tempCNN\\nwithin-site\\narchitecture*', 'Multi-tempCNN\\nout-of-site\\narchitecture*',\n",
    "         'Multi-tempCNN\\nout-of-site\\narchitecture', 'Multi-tempCNN\\nwithin-site\\narchitecture',\n",
    "         'Modis-tempCNN', 'Modis-tempCNN',]\n",
    "scenarios = ['Within-site', 'Out-of-site', 'Within-site', 'Out-of-site', 'Within-site', 'Out-of-site',]\n",
    "y_labels = ['RMSE (%)', 'Bias (%)', '$R^2$', 'RMSE (%)', 'Bias (%)', '$R^2$',]\n",
    "fig_labels = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)', ]\n",
    "stats_df = pd.concat(all_stats, keys = pd.MultiIndex.from_arrays([tests, scenarios], names=('Architecture', 'Scenario')))\n",
    "stats_df = stats_df[['RMSE', 'Bias', 'R2']].stack().reset_index()\n",
    "stats_df = stats_df.rename(columns={'level_3': 'Statistic', 0: 'Value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9b504-5c1d-4bc0-9196-903a886db69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_size = 7\n",
    "title_size = 10\n",
    "plt.rcParams.update({'font.size': font_size})\n",
    "fig = plt.figure(constrained_layout=False, figsize=(8.617, 2.87), dpi=500, linewidth=2, edgecolor=\"black\")\n",
    "sns.set_context(\"paper\", rc={\"font.size\": font_size, \"axes.titlesize\": title_size, \"axes.labelsize\": font_size})   \n",
    "sns.set_style(\"ticks\")\n",
    "palette = [sns.color_palette()[0], sns.color_palette()[0], sns.color_palette()[1], sns.color_palette()[1], sns.color_palette()[2]]\n",
    "g = sns.catplot(data=stats_df, y='Value', x='Architecture', col='Statistic', row='Scenario', hue='Architecture',\n",
    "                kind=\"point\", markers=['*', '*', 'o', 'o', 'h'], palette=palette, join=False,  scale=1.75,\n",
    "                sharey=False, sharex=False)\n",
    "fig = g.fig\n",
    "fig.set_size_inches(6.93, 5.0) #(6.930, 4.75)\n",
    "fig.set_dpi(500)\n",
    "fig.set_edgecolor('black')\n",
    "fig.set_linewidth(2)\n",
    "for n, ax in enumerate(g.axes.ravel()):\n",
    "    xpos = -24 if n < 2 else -29 if n in [2, 5] else -30\n",
    "    ax.annotate(fig_labels[n], xy=(0, 1), xytext=(xpos, 5), ha='center', va='bottom', xycoords='axes fraction', textcoords='offset points', fontsize=font_size)\n",
    "    ax.xaxis.set_tick_params(labelsize=font_size, rotation=90)\n",
    "    ax.yaxis.set_tick_params(labelsize=font_size)\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel(y_labels[n])\n",
    "    if n == 1:\n",
    "        ax.set_title('Within-site Scenario\\n', size=title_size)\n",
    "    elif n == 4:\n",
    "        ax.set_title('Out-of-site Scenario\\n', size=title_size)\n",
    "    else:\n",
    "        ax.set_title(None)\n",
    "    for line_ in ax.get_lines():\n",
    "        line_.set_color('black')\n",
    "        line_.set_lw(1.25)\n",
    "    annots = {}\n",
    "    for path in ax.collections:\n",
    "        points = path.get_offsets()\n",
    "        point = points[~points.mask]\n",
    "        if len(point) >= 2:\n",
    "            annots[point[0]] = {'mean': round(point[1], 4)}\n",
    "    for line_ in ax.get_lines():\n",
    "        x_pos = line_.get_data()[0][0]\n",
    "        ci = line_.get_data()[1]\n",
    "        if ci[0] == ci[0]:\n",
    "            annots[x_pos]['ci'] = np.round(ci, 4)\n",
    "    for x, dict_ in annots.items():\n",
    "        ha = 'center'\n",
    "        if n in [2, 5]:\n",
    "            if n == 2:\n",
    "                ax.set_ylim([0.56, 0.72])\n",
    "                ax.set_yticks(np.arange(0.56, 0.73, 0.04))\n",
    "            else:\n",
    "                ax.set_ylim([0.44, 0.54])\n",
    "            x_pos = x\n",
    "            y_pos = dict_['mean'] * (0.99 if x == 0 else 1.015)\n",
    "            va = 'top' if x == 0 else 'bottom'\n",
    "            ci = (dict_['ci'][1] - dict_['ci'][0]) / 2\n",
    "            text = f\"mean: {round(dict_['mean'],3):.3f}\\nCI: $\\pm${ci:.3f}\"\n",
    "        elif n in [1, 4]:\n",
    "            if n == 1:\n",
    "                ax.set_ylim([-4.5, 1.75])\n",
    "            else:\n",
    "                ax.set_ylim([-4.5, 1])\n",
    "            y_off = 0.4\n",
    "            x_pos = 0.1 if x == 0 else x\n",
    "            va = 'bottom' if x == 2 else 'top'\n",
    "            y_off = y_off if x == 2 else -y_off\n",
    "            y_pos = dict_['mean'] + y_off\n",
    "            ci = (dict_['ci'][1] - dict_['ci'][0]) / 2\n",
    "            text = f\"mean: {round(dict_['mean'],2):.2f}%\\nCI: $\\pm${ci:.2f}\"\n",
    "        else:\n",
    "            if n == 0:\n",
    "                ax.set_ylim([20, 25])\n",
    "                y_off = 0.015\n",
    "            elif n == 3:\n",
    "                ax.set_ylim([25, 28])\n",
    "                y_off = 0.0075\n",
    "            x_pos = 0.9 if x == 1 else (x + 0.1)\n",
    "            va = 'bottom' if x == 0 else 'top'\n",
    "            y_off = y_off if x == 0 else -y_off\n",
    "            y_pos = dict_['mean'] * (1 + y_off)\n",
    "            ci = (dict_['ci'][1] - dict_['ci'][0]) / 2\n",
    "            text = f\"mean: {round(dict_['mean'],2):.2f}%\\nCI: $\\pm${ci:.2f}\"\n",
    "        ax.annotate(text, (x_pos, y_pos), va=va, ha=ha, size=font_size)\n",
    "output_dir = common.FIGURES_DIR\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.8)\n",
    "fig.savefig(os.path.join(output_dir, 'Comparisons.jpeg'), format=\"jpeg\", bbox_inches='tight', pad_inches=0.2, dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701cf018-30a2-4fa0-8635-167601ec9423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFMC",
   "language": "python",
   "name": "lfmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
