{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7eb361-aaa3-4f11-a1fc-8efe3cdcffbd",
   "metadata": {},
   "source": [
    "# Ablation Tests Results\n",
    "Display evaluation metrics and create figures for the ablation test results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3089bc-1ab6-4f9f-90ee-55ef5127b45e",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca3718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import initialise\n",
    "import common\n",
    "from display_utils import display_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57a37c-23a7-4e7e-b080-3e1236f8cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS = ['within-site', 'out-of-site']\n",
    "EXPERIMENTS = ['omit_one', 'ablation']\n",
    "model_dirs = ['_'.join([s, t]) for t in EXPERIMENTS for s in SCENARIOS]\n",
    "precision = 3       # floating point precision for results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b6fa70-e530-4e60-a5bb-284863dee0d9",
   "metadata": {},
   "source": [
    "### Function to Load Predictions and Statistics, and Generate Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db5d8f-1732-478b-b406-b49f366e5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(experiment_name):\n",
    "    pre_ = precision + 1\n",
    "    stats_fname = f\"ensemble{common.ENSEMBLE_SIZE:02}_stats.csv\"\n",
    "    scenario = experiment_name.split('_')[0]\n",
    "    scenario_dir = '_'.join([scenario, 'models'])\n",
    "    ens_stats = [pd.read_csv(os.path.join(common.MODELS_DIR, scenario_dir, stats_fname), index_col=(0,1))]\n",
    "\n",
    "    model_dir = os.path.join(common.MODELS_DIR, experiment_name)\n",
    "    with open(os.path.join(model_dir, 'experiment.json'), 'r') as f:\n",
    "        experiment = json.load(f)\n",
    "    tests = ['Proposed model'] + experiment['testNames']\n",
    "    stats_fname = f\"ensemble{common.ENSEMBLE_SIZE:02}_stats.csv\"\n",
    "    for num, test in enumerate(tests[1:]):\n",
    "        test_name = f'test{num}'\n",
    "        ens_stats.append(pd.read_csv(os.path.join(model_dir, test_name, stats_fname), index_col=(0,1)))\n",
    "    ens_means = [stats_.mean(axis=1).unstack() for stats_ in ens_stats]\n",
    "\n",
    "    ci_dict = {}\n",
    "    for n, t in enumerate(ens_stats):\n",
    "        a = t.loc[common.ANALYSIS_MODEL].T\n",
    "        ci = stats.t.interval(common.CI, len(a)-1, loc=np.mean(a), scale=stats.sem(a))\n",
    "        ci = ((ci[1] - ci[0]) / 2).round(pre_)\n",
    "        ci_dict[tests[n]] = pd.DataFrame([ens_means[n].loc[common.ANALYSIS_MODEL].array, ci], index=['mean', 'ci'], columns=a.columns)\n",
    "    df_list = []\n",
    "    for num, test in enumerate(tests):\n",
    "        df_dict={}\n",
    "        df_dict.update(ci_dict[test].RMSE.round(pre_).add_prefix('RMSE_').to_dict())\n",
    "        df_dict.update(ci_dict[test].Bias.round(pre_).add_prefix('Bias_').to_dict())\n",
    "        df_dict.update(ci_dict[test].R2.round(pre_).add_prefix('R2_').to_dict())\n",
    "        df_list.append(df_dict)\n",
    "    return pd.DataFrame(df_list, index=tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace238c-07a1-4340-97be-c30767408d16",
   "metadata": {},
   "source": [
    "### Function to format figure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913dc369-1e73-4fb3-b97b-aa661065c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_figure_data(ens_stats, test_names, drop_tests=[None, None]):\n",
    "    stats1_df = [None, None]\n",
    "    temp_df = pd.concat(ens_stats[0], keys=pd.MultiIndex.from_arrays([test_names[0], ['Within-site'] * len(test_names[0])]), names=['Test name', 'Scenario'])\n",
    "    if drop_tests[0] is not None:\n",
    "        temp_df = temp_df.drop(drop_tests[0], level=0)\n",
    "    temp_df = temp_df[['RMSE', 'Bias', 'R2']].stack().reset_index()\n",
    "    stats1_df[0] = temp_df.rename(columns={'level_3': 'Statistic', 0: 'Value'})\n",
    "    temp_df = pd.concat(ens_stats[1], keys=pd.MultiIndex.from_arrays([test_names[1], ['Out-of-site'] * len(test_names[1])]), names=['Test name', 'Scenario'])\n",
    "    if drop_tests[1] is not None:\n",
    "        temp_df = temp_df.drop(drop_tests[1], level=0)\n",
    "    temp_df = temp_df[['RMSE', 'Bias', 'R2']].stack().reset_index()\n",
    "    stats1_df[1] = temp_df.rename(columns={'level_3': 'Statistic', 0: 'Value'})\n",
    "    return pd.concat(stats1_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67511cf4-28a9-43ee-887a-f31d6ebce316",
   "metadata": {},
   "source": [
    "### Function to format labels and add annotations to the sub-plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd2af4-9bba-4a2b-905b-f0aee7fb001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_subplot(n, ax):\n",
    "    xpos = -30 \n",
    "    ax.annotate(fig_labels[n], xy=(0, 1), xytext=(xpos, 5), ha='center', va='bottom', xycoords='axes fraction', textcoords='offset points', fontsize=font_size)\n",
    "    ax.xaxis.set_tick_params(labelsize=font_size, rotation=90)\n",
    "    ax.yaxis.set_tick_params(labelsize=font_size)\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel(y_labels[n])\n",
    "    if n == 1:\n",
    "        ax.set_title('Within-site Scenario\\n', size=title_size)\n",
    "    elif n == 4:\n",
    "        ax.set_title('Out-of-site Scenario\\n', size=title_size)\n",
    "    else:\n",
    "        ax.set_title(None)\n",
    "    for line_ in ax.get_lines():\n",
    "        line_.set_color('black')\n",
    "        line_.set_lw(1.25)\n",
    "    annots = {}\n",
    "    for path in ax.collections:\n",
    "        points = path.get_offsets()\n",
    "        point = points[~points.mask]\n",
    "        if len(point) >= 2:\n",
    "            annots[point[0]] = {'mean': round(point[1], 4)}\n",
    "    for line_ in ax.get_lines():\n",
    "        x_pos = line_.get_data()[0][0]\n",
    "        ci = line_.get_data()[1]\n",
    "        if ci[0] == ci[0]:\n",
    "            annots[x_pos]['ci'] = np.round(ci, 4)\n",
    "    return ax, annots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb03058-c933-44e7-a66f-65a82741060f",
   "metadata": {},
   "source": [
    "## Display Results\n",
    "Display the RMSE, Bias, and R2 mean and CI for each test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99916e1f-8aec-421d-a0a5-bac785cb5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [get_results(m) for m in model_dirs]\n",
    "for e, ex in enumerate(EXPERIMENTS):\n",
    "    print(f'\\nExperiment: {ex}')\n",
    "    print('====================\\n')\n",
    "    s = len(SCENARIOS)\n",
    "    display_frames(results[e*s:e*s+s], SCENARIOS, precision=precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f06d5a5-e7a1-4cc8-8c18-a37b4d6c8f7b",
   "metadata": {},
   "source": [
    "## Generate the Ablation Test Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f1936-bc15-4f5a-ad29-02f2461850e8",
   "metadata": {},
   "source": [
    "### Load Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20005301-b97d-4e2c-b1fa-32fc86fe1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_stats = [[], [], [], []]\n",
    "stats_fname = f\"ensemble{common.ENSEMBLE_SIZE:02}_stats.csv\"\n",
    "for num, dir_ in enumerate(sorted(glob.glob(os.path.join(common.MODELS_DIR, '*site_models')), reverse=True)):\n",
    "    ens_stats[num].append(pd.read_csv(os.path.join(dir_, stats_fname), index_col=(0,1)).loc[common.ANALYSIS_MODEL].T)\n",
    "    ens_stats[num+2].append(pd.read_csv(os.path.join(dir_, stats_fname), index_col=(0,1)).loc[common.ANALYSIS_MODEL].T)\n",
    "\n",
    "all_tests = []\n",
    "for num, model_dir in enumerate(model_dirs):\n",
    "    with open(os.path.join(common.MODELS_DIR, model_dir, 'experiment.json'), 'r') as f:\n",
    "        experiment = json.load(f)\n",
    "    tests = experiment['testNames']\n",
    "    all_tests.append(['Proposed model'] + tests)\n",
    "    for t_num, test in enumerate(tests):\n",
    "        test_name = f'test{t_num}'\n",
    "        ens_stats[num].append(pd.read_csv(os.path.join(common.MODELS_DIR, model_dir, test_name, stats_fname), index_col=(0,1)).loc[common.ANALYSIS_MODEL].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3358c9-0966-4d4f-914c-93c527a5159f",
   "metadata": {},
   "source": [
    "### Labels and settings for use in the figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a1408-5402-4f14-9274-5190d92a0c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests[0][1] = 'Without meteorology'\n",
    "all_tests[1][1] = 'Without meteorology'\n",
    "all_tests[2] = ['Proposed', 'Conv filters', 'Conv layers', 'FC layers', 'FC units', 'Dropout', 'Batch size']\n",
    "all_tests[3] = ['Proposed', 'Conv filters', 'FC layers', 'FC units', 'x', 'Dropout', 'Batch size', 'Epochs']\n",
    "o = all_tests[0]\n",
    "order1 = [o[0], o[1], o[2], o[4], o[5], o[3]]\n",
    "y_labels = ['RMSE (%)', 'Bias (%)', '$R^2$', 'RMSE (%)', 'Bias (%)', '$R^2$',]\n",
    "fig_labels = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)', ]\n",
    "\n",
    "font_size = 7\n",
    "title_size = 10\n",
    "sns.set_context(\"paper\", rc={\"font.size\": font_size, \"axes.titlesize\": title_size, \"axes.labelsize\": font_size})   \n",
    "sns.set_style(\"ticks\")\n",
    "palette = [sns.color_palette()[0], sns.color_palette()[1], sns.color_palette()[2], sns.color_palette()[4],\n",
    "           sns.color_palette()[5], sns.color_palette()[6], sns.color_palette()[7], sns.color_palette()[8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff837131-eae5-4939-8d86-a9942e31a476",
   "metadata": {},
   "source": [
    "### Inputs Ablation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84469c07-ac8e-4fcb-b3b5-80aab706ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats1_df = format_figure_data(ens_stats[0:2], all_tests[0:2])\n",
    "g = sns.catplot(data=stats1_df, y='Value', x='Test name', col='Statistic', row='Scenario', hue='Test name', order=order1,\n",
    "                kind=\"point\", markers=['*', 'o', 'h', 'p', 'P', 'd'], palette=palette, join=False,  scale=1.75,\n",
    "                sharey=False, sharex=True)\n",
    "fig = g.fig\n",
    "fig.set_size_inches(6.84, 4.75)\n",
    "fig.set_dpi(500)\n",
    "fig.set_edgecolor('black')\n",
    "fig.set_linewidth(2)\n",
    "for n, ax in enumerate(g.axes.ravel()):\n",
    "    ax, annots = format_subplot(n, ax)\n",
    "    for x, dict_ in annots.items():\n",
    "        ha = 'center'\n",
    "        if n == 0:\n",
    "            ax.set_ylim([20.5, 21.75])\n",
    "            y_off = -0.065 if x in [0, 5] else 0.065\n",
    "            va = 'top' if x in [0, 5] else 'bottom'\n",
    "        elif n == 1:\n",
    "            ax.set_ylim([-0.4, 0.8])\n",
    "            va = 'top' if x == 5 else 'bottom'\n",
    "            y_off = -0.05 if x == 5 else 0.05\n",
    "        elif n == 2:\n",
    "            ax.set_ylim([0.67, 0.70])\n",
    "            y_off = 0.0015 if x in [2, 5] else -0.002\n",
    "            va = 'bottom' if x in [2, 5] else 'top'\n",
    "        elif n == 3:\n",
    "            ax.set_ylim([24.9, 27])\n",
    "            y_off = 0.1 if x in [2, 4] else -0.1\n",
    "            va = 'bottom' if x in [2, 4] else 'top'\n",
    "        elif n == 4:\n",
    "            ax.set_ylim([-0.1, 0.8])\n",
    "            va = 'top' if x == 2 else 'bottom'\n",
    "            y_off = -0.05 if x == 2 else 0.05\n",
    "        else:  # n == 5:\n",
    "            ax.set_ylim([0.46, 0.56])\n",
    "            y_off = 0.005 if x in [0, 3, 5] else -0.007\n",
    "            va = 'bottom' if x in [0, 3, 5] else 'top'\n",
    "        y_pos = dict_['mean'] + y_off\n",
    "        ci = (dict_['ci'][1] - dict_['ci'][0]) / 2\n",
    "        if n in [2, 5]:\n",
    "            x_pos = 0.4 if x == 0 else x\n",
    "            text = r\"$\\bar x$\" + f\": {round(dict_['mean'],3):.3f}\\nCI: $\\pm${ci:.3f}\"\n",
    "        else:\n",
    "            x_pos = 0.3 if x == 0 else x\n",
    "            text = r\"$\\bar x$\" + f\": {round(dict_['mean'],2):.2f}\\nCI: $\\pm${ci:.2f}\"\n",
    "        ax.annotate(text, (x_pos, y_pos), va=va, ha=ha, size=font_size)\n",
    "output_dir = common.FIGURES_DIR\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "fig.savefig(os.path.join(output_dir, 'Input ablation.jpeg'), format=\"jpeg\", bbox_inches='tight', pad_inches=0.2, dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee802a46-ca0e-4fa1-8ab0-54ec938dd934",
   "metadata": {},
   "source": [
    "### Architecture Ablation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccaaffb-65a9-422f-9e07-11a7640a952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2_df = format_figure_data(ens_stats[2:4], all_tests[2:4], [None, all_tests[3][4]])\n",
    "g = sns.catplot(data=stats2_df, y='Value', x='Test name', col='Statistic', row='Scenario', hue='Test name',\n",
    "                kind=\"point\", markers=['*', 'o', 'h', 'p', 'P', 'd', '^', 'X'], palette=palette, join=False,  scale=1.75,\n",
    "                sharey=False, sharex=False)\n",
    "fig = g.fig\n",
    "fig.set_size_inches(6.8075, 5.0)\n",
    "fig.set_dpi(500)\n",
    "fig.set_edgecolor('black')\n",
    "fig.set_linewidth(2)\n",
    "for n, ax in enumerate(g.axes.ravel()):\n",
    "    ax, annots = format_subplot(n, ax)\n",
    "    for x, dict_ in annots.items():\n",
    "        ha = 'center'\n",
    "        x_pos = 0.4 if x == 0 else x\n",
    "        if n == 0:\n",
    "            ax.set_ylim([20.25, 22.5])\n",
    "            y_off = 0.15 if x in [1, 2, 6] else -0.15\n",
    "            va = 'bottom' if x in [1, 2, 6] else 'top'\n",
    "            x_pos = x_pos - 0.2 if x == 1 else x_pos - 0.2 if x == 3 else x_pos\n",
    "        elif n == 1:\n",
    "            ax.set_ylim([-2.6, 0.5])\n",
    "            y_off = 0.15 if x in [0, 2, 3, 5] else -0.15\n",
    "            va = 'bottom' if x in [0, 2, 3, 5] else 'top'\n",
    "            x_pos = x_pos + 0.3 if x == 2 else x_pos\n",
    "        elif n == 2:\n",
    "            ax.set_ylim([0.645, 0.705])\n",
    "            y_off = -0.0035 if x in [1, 2, 4] else 0.0035\n",
    "            va = 'top' if x in [1, 2, 4] else 'bottom'\n",
    "            x_pos = x_pos + 0.1 if x in [0, 4] else x_pos - 0.3 if x == 3 else x_pos\n",
    "        elif n == 3:\n",
    "            ax.set_ylim([24.95, 26.2])\n",
    "            va = 'bottom' if x in [0, 2, 5] else 'top'\n",
    "            y_off = 0.075 if x in [0, 2, 5] else -0.075\n",
    "        elif n == 4:\n",
    "            ax.set_ylim([-1.5, 1.5])\n",
    "            va = 'bottom' if x in [0, 1, 4, 5] else 'top'\n",
    "            y_off = 0.15 if x in [0, 1, 4, 5] else -0.15\n",
    "        else:  # n == 5:\n",
    "            ax.set_ylim([0.50, 0.55])\n",
    "            y_off = -0.003 if x in [0, 2, 5] else 0.003\n",
    "            va = 'top' if x in [0, 2, 5] else 'bottom'\n",
    "            x_pos = x_pos + 0.1 if x == 0 else x_pos\n",
    "        y_pos = dict_['mean'] + y_off\n",
    "        ci = (dict_['ci'][1] - dict_['ci'][0]) / 2\n",
    "        if n in [2, 5]:\n",
    "            text = r\"$\\bar x$\" + f\": {round(dict_['mean'],3):.3f}\\nCI: $\\pm${ci:.3f}\"\n",
    "        else:\n",
    "            text = r\"$\\bar x$\" + f\": {round(dict_['mean'],2):.2f}\\nCI: $\\pm${ci:.2f}\"\n",
    "        ax.annotate(text, (x_pos, y_pos), va=va, ha=ha, size=font_size)\n",
    "output_dir = common.FIGURES_DIR\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.8)\n",
    "fig.savefig(os.path.join(output_dir, 'Architecture ablation.jpeg'), format=\"jpeg\", bbox_inches='tight', pad_inches=0.2, dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593a224-65c7-4523-97f6-465df8b2e10f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFMC",
   "language": "python",
   "name": "lfmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
