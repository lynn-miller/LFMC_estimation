{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-site run times\n",
    "Version of the out-of-site ablation tests that gets the run-times for the final model and architecture ablation tests.\n",
    "#### Notes\n",
    "- Only one fold model is created for each run\n",
    "- Only 20 runs per test - i.e. timings are for one ensemble of twenty runs.\n",
    "- No parallel running of tests\n",
    "- The first test (test0) is the proposed model, so other tests are offset by 1 compared to the full ablation test (e.g. the dropout test is test4 here and test3 in the ablation test)\n",
    "- By default, training times are output to the `train_stats.csv` file, so these could also be obtained from the ablation tests model directories. This notebook allows testing under more controlled conditions - e.g. if the full runs are run in a shared environment they may not be accurate/consistent due to the server workload. So this is a cut-down version that can run in a small dedicated environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import initialise\n",
    "import common\n",
    "from modelling_functions import create_models, run_experiment\n",
    "from architecture_out_of_site import model_params\n",
    "from model_parameters import ModelParams, ExperimentParams\n",
    "import scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input files\n",
    "Change these settings as required\n",
    "- `modis_csv`: The file containing extracted MODIS data for each sample, created by `Extract MODIS Data.ipynb`\n",
    "- `prism_csv`: The file containing extracted PRISM data for each sample, created by `Extract PRISM Data.ipynb`\n",
    "- `aux_csv`: The file containing extracted sample labels, DEM, climate zone and other auxiliary data, created by `Extract Auxiliary Data.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_csv = os.path.join(common.DATASETS_DIR, 'modis_365days.csv')\n",
    "prism_csv = os.path.join(common.DATASETS_DIR, 'prism_365days.csv')\n",
    "aux_csv = os.path.join(common.DATASETS_DIR, 'samples_365days.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up experiment parameters\n",
    "If the experiment dictionary contains a 'tests' key that is not 'falsy' (False, None, 0, empty list) it is assumed to be a list of tests to run. Each test will run with the specified model parameters. Model parameters not specified will be the same for each test, as set in the main model_params dictionary. A failed run can be restarted by setting the 'restart' key to the test that failed. This test and the remaining tests will then be run.\n",
    "\n",
    "If 'tests' is 'falsy' then a single test will be run using the parameters in the main model_params dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment = ExperimentParams({\n",
    "    'name': 'out-of-site_timings',\n",
    "    'description': 'Timings for out-of-site architecture changes',\n",
    "    'tests': [\n",
    "        {'testName': 'Proposed model'},\n",
    "        {'testName': 'Conv filters: 32',\n",
    "         'blocks': {\n",
    "             'opticalConv': [{'filters': 32}, {'filters': 32}, {'filters': 32}],\n",
    "             'weatherConv': [{'filters': 32}, {'filters': 32}, {'filters': 32}]\n",
    "             },\n",
    "        },\n",
    "        {'testName': 'Dense layers: 2', 'blocks': {'fc': [{'units': 128}, {'units': 128}]}},\n",
    "        {'testName': 'Dense units: 256', 'blocks': {'fc': [{'units': 256}]}},\n",
    "        {'testName': 'Dropout: 0.5', 'dropoutRate': 0.5},\n",
    "        {'testName': 'Batch size: 32', 'batchSize': 32},\n",
    "        {'testName': 'Epochs: 100', 'epochs': 100},\n",
    "    ],\n",
    "    'restart': None,\n",
    "})\n",
    "\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters settings\n",
    "To find out more about any parameter, run `model_params.help('<parameter>')`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Customize model parameters\n",
    "scenarios.out_of_site_scenario(model_params)\n",
    "model_params['modelName'] = experiment['name']\n",
    "model_params['description'] = experiment['description']\n",
    "model_params['samplesFile'] = aux_csv\n",
    "model_params['modelDir'] = os.path.join(common.MODELS_DIR, model_params['modelName'])\n",
    "model_params['splitFolds'] = 0\n",
    "model_params['testSize'] = 0.1\n",
    "\n",
    "model_params.add_input('optical', {'filename': modis_csv, 'channels': 7})\n",
    "model_params.add_input('weather', {'filename': prism_csv, 'channels': 7})\n",
    "\n",
    "model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and run the models\n",
    "Builds and trains the LFMC models. After training each model, several derived models are created and evaluated. The full list of models is:\n",
    "- `base` - The fully trained model\n",
    "- `best` - A model using the checkpoint with the best training loss\n",
    "- `merge10` - A model created by merging the last 10 checkpoints. The checkpoints are merged by averaging the corresponding weights from each model.\n",
    "- `ensemble10` - An ensembled model of the last 10 checkpoints. This model averages the predictions made by each model in the ensemble to make the final prediction.\n",
    "- `merge_best10` - Similar to the merge10 model, but uses the 10 checkpoints with the lowest training/validation losses.\n",
    "\n",
    "All models, predictions, evaluation statistics, and plots of test results are saved to `model_dir`, with each test and run saved to a separate sub-directory. For each model created, predictions and evaluation statistics are also returned as attributes of the `model` object. These are stored as nested lists, the structure for a full experiment is:\n",
    "- Tests (omitted if not an experiment)\n",
    "  - Runs (omitted for a single run)\n",
    "    - Folds (for k-fold splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = run_experiment(experiment, model_params)\n",
    "for model in models:\n",
    "    display(getattr(model, 'test_stats', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the training times\n",
    "Time are Tensorflow/Keras model training time and excludes data preparation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_times = []\n",
    "for test in models:\n",
    "    run_time = 0\n",
    "    for run in test:\n",
    "        df = pd.read_csv(os.path.join(run.model_dir, 'train_stats.csv'))\n",
    "        run_time += df.trainTime[0]\n",
    "    weights = df.trainableWeights[0]\n",
    "    train_times.append([run_time/60, run_time/60/len(test), weights])\n",
    "pd.DataFrame(train_times, index=experiment['testNames'],\n",
    "             columns=['ensemble_time', 'single_time', 'num_params']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFMC",
   "language": "python",
   "name": "lfmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
