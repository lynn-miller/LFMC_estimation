""" Out-of_site Mapping Model
Creates the out-of-site model used for mapping. It creates the ensemble
of 20 models and saves the Keras models as HDF5 files. These files can
then be loaded and used to generate the LFMC estimates needed to create
LFMC maps.
""" 

import os
import numpy as np
import pandas as pd

import initialise
from model_utils import reshape_data
from modelling_functions import create_models
from model_parameters import ModelParams


if __name__ == '__main__':
    # =============================================================================
    # Directories and Input files
    #
    # Change these settings as required
    # - `input_dir`: Directory containing the data extracted from GEE and
    #   Globe-LFMC, the outputs from running the `Extract DEM Data.ipynb`
    #   and `Extract MODIS Data.ipynb` notebooks.
    # - `output_dir`: A sub-directory called `model_params['modelName']`
    #   (`Scenario_A`) will be created in this directory, where all
    #   outputs generated by this notebook will be written. 
    # - `temp_dir`: A temporary directory where model checkpoints are
    #   created. This directory should exist and be empty.
    # - `modis_csv`: The file containing extracted MODIS data for each
    #   sample, created by `Extract MODIS Data.ipynb`
    # - `prism_csv`: The file containing extracted PRISM data for each
    #   sample, created by `Extract PRISM Data.ipynb`
    # - `aux_csv`: The file containing extracted sample labels, DEM, climate zone
    #   and other auxiliary data, created by `Extract Auxiliary Data.ipynb`.
    #     
    # =============================================================================
    input_dir = r'G:\My Drive\LFMC Data\LFMC_ensembles\Datasets'
    output_dir = r'G:\My Drive\LFMC Data\LFMC_ensembles\Models'
    temp_dir = r'C:\Temp\LFMC'
    modis_csv = os.path.join(input_dir, 'modis_365days.csv')
    prism_csv = os.path.join(input_dir, 'prism_365days.csv')
    aux_csv = os.path.join(input_dir, 'samples_365days.csv')

    # =============================================================================
    # Model Parameters - Leave these parameters as set for the out-of-site Scenario
    # =============================================================================
    model_params = ModelParams(modis_layers=3, prism_layers=3, fc_layers=1)

    model_params['modelClass'] = 'LfmcTempCnn'
    model_params['dataSources'] = ['modis', 'prism', 'aux'] 
    model_params['modisFilename'] = modis_csv
    model_params['prismFilename'] = prism_csv
    model_params['auxFilename'] = aux_csv
    model_params['auxAugment'] = True
    model_params['auxColumns'] = ['Elevation', 'Slope', 'Aspect_sin', 'Aspect_cos',
                                  'Long_sin', 'Long_cos', 'Lat_norm']
    model_params['auxOneHotCols'] = ['Czone3']
    model_params['dropoutRate'] = 0
    model_params['epochs'] = 50
    model_params['batchSize'] = 512

    model_params['fc'][0]['units'] = 128

    model_params['modisConv'][0]['poolSize'] = 2
    model_params['modisConv'][1]['poolSize'] = 3
    model_params['modisConv'][2]['poolSize'] = 4

    model_params['prismConv'][0]['poolSize'] = 2
    model_params['prismConv'][1]['poolSize'] = 3
    model_params['prismConv'][2]['poolSize'] = 4

    # =============================================================================
    # Parameters for mapping models
    # =============================================================================
    model_params['saveModels'] = ['base']   # Save the Keras models so they can be used for map-wide estimates
    model_params['splitMethod'] = 'byYear'  # Deliberate! so 2017 data is not included in the model
    model_params['splitYear'] = 2017        # Deliberate! so 2017 data is not included in the model
    model_params['modelRuns'] = 20          # Generate 20 models for ensemble

    # =============================================================================
    # These parameters can be changed. To find out more about any parameter,
    # run `ModelParams().help('<parameter>')` 
    # =============================================================================
    model_params['modelName'] = 'out-of-site_map2017'
    model_params['description'] = 'Create an ensemble of out-of-site models for 2017 LFMC maps'
    model_params['seedList'] = [
        441, 780, 328, 718, 184, 372, 346, 363, 701, 358,
        566, 451, 795, 237, 788, 185, 397, 530, 758, 633,
        632, 941, 641, 519, 162, 215, 578, 919, 917, 585,
        914, 326, 334, 366, 336, 413, 111, 599, 416, 230,
        191, 700, 697, 332, 910, 331, 771, 539, 575, 457
    ]
    # model_params['gpuDevice'] = 1
    # model_params['gpuMemory'] = 3800
    # model_params['maxWorkers'] = 5

    model_params['tempDir'] = temp_dir
    model_params['modelDir'] = os.path.join(output_dir, model_params['modelName'])
    
    
    restart = False     # Change to True if retrying/restarting this script
    if not os.path.exists(model_params['modelDir']):
        os.makedirs(model_params['modelDir'])
    elif not restart:   # Don't over-write something important!
        raise FileExistsError(f"{model_params['modelDir']} exists but restart not requested")

    # =============================================================================
    # Prepare the data
    # 
    # =============================================================================
    modis_data = pd.read_csv(modis_csv, index_col=0)
    x_modis = reshape_data(np.array(modis_data), model_params['modisChannels'])
    print(f'Modis shape: {x_modis.shape}')

    prism_data = pd.read_csv(prism_csv, index_col=0)
    x_prism = reshape_data(np.array(prism_data), model_params['prismChannels'])
    print(f'Prism shape: {x_prism.shape}')

    aux_data = pd.read_csv(aux_csv, index_col=0)
    y = aux_data[model_params['targetColumn']]

    # =============================================================================
    # Builds and trains the LFMC models. After training the models, several
    # derived models are created and evaluated. The full list of models is:
    # - `base` - The fully trained model. The Multi-tempCNN models use this model.
    # - `best` - A model using the checkpoint with the best training loss
    # - `merge10` - A model created by merging the last 10 checkpoints (merged
    #   by averaging the corresponding weights from each model).
    # - `ensemble10` - An ensembled model of the last 10 checkpoints. This model
    #   averages the predictions made by each model in the ensemble to make the
    #   final prediction.
    # - `merge_best10` - Similar to the merge10 model, but uses the 10 checkpoints
    #   with the lowest training/validation losses.
    # 
    # All models (if requested), predictions, and evaluation statistics
    # are saved to `model_dir`, with each run saved to a separate sub-directory
    # For each model created, predictions and evaluation statistics are also
    # returned as attributes of the model. These are stored as nested lists, the
    # structure is:
    # - Runs (omitted for a single run)
    #   - Folds (for k-fold splitting)
    # 
    # =============================================================================
    X = {'modis': x_modis, 'prism': x_prism}
    with open(os.path.join(model_params['modelDir'], 'model_params.json'), 'w') as f:
        model_params.save(f)
    models = create_models(model_params, aux_data, X, y)

    print('\n\nResults Summary')
    print('===============\n')
    print(getattr(models, 'all_stats', None))
