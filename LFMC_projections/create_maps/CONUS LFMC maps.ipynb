{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2b26aa2",
   "metadata": {},
   "source": [
    "# Generate CONUS LFMC Image\n",
    "#### Description\n",
    "Creates a GeoTiff image of LFMC predictions that can be used to produce LFMC maps.\n",
    "\n",
    "#### Input Images\n",
    "1. An image of auxiliary data - latitude, longitude, elevation, slope, aspect and climate zone\n",
    "2. Images of MODIS data for at least 1 year prior to the mapping date\n",
    "3. Images of PRISM data for at least 1 year prior to the mapping date  \n",
    "Note: Band names for PRISM data are confusing. When GEE converts an image collection to an image, it includes the date in the band name. Timestamps on PRISM data are midday, so when they are converted (rounded) to a date, this becomes the following day. So in the extracted GeoTiffs, bands for 2016-10-01 data will named for 2016-10-02!\n",
    "\n",
    "#### Other Inputs\n",
    "1. Model directory - this should contain \"run\" directories - one for each model in the ensemble.\n",
    "2. Data used to train the model - The notebook extracts normalisation bounds and one-hot encodings needed to prepare the input data. The normalisation bounds are saved to csv files, so if these files already exist, bounds can be loaded from these instead.\n",
    "3. Legend file for Koppen climate zones. This should be a CSV as created by the \"Extract Auxiliary Data.ipynb\" notebook. Used to convert the climate zone numbers in the auxiliary input into climate zone codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "import initialise\n",
    "import common\n",
    "from model_list import ModelList\n",
    "from model_parameters import ModelParams\n",
    "from data_prep_utils import reshape_data, normalise, load_bounds, create_onehot_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82073ab9-059e-432c-8df9-3848c9c24ab7",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "The next two cells set up the parameters for a specific map. Uncomment and run the cell for the required map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcbb9e-a05b-4b49-a76c-6d6e569e1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LFMC_SCENARIO = 'Nowcasting'\n",
    "MODEL_DIR = os.path.join(common.MODELS_DIR, 'final_models', 'test0')\n",
    "TS_OFFSET = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c21fb2-a634-4e39-ac3b-71db0b86d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFMC_SCENARIO = 'Projection'\n",
    "# MODEL_DIR = os.path.join(common.MODELS_DIR, 'final_models', 'test1')\n",
    "# TS_OFFSET = 91"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86743c1f-bc0d-49eb-8a22-25b46da79a95",
   "metadata": {},
   "source": [
    "Set the mapping date. In the paper, maps for the dates '2018-04-01' and '2018-10-01' are provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94060489-0e59-47b1-b976-dd25934c1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_DATE = '2018-04-01'\n",
    "# MAP_DATE = '2018-10-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9c4a0-c10f-4f34-8c06-c45b21544ca9",
   "metadata": {},
   "source": [
    "### Other settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a332d24-24e7-4b3a-9a4f-d061273adb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DERIVED_MODEL = common.ANALYSIS_MODEL\n",
    "IMAGE_DIR = 'GEE_EPSG-4326_2000'\n",
    "TS_DAYS = 365\n",
    "INTERP_METHOD = 'linear'\n",
    "INTERP_MAXGAP = None\n",
    "INTERP_DIRECTION = 'both'\n",
    "NODATA = -999\n",
    "FLOAT_PRE = 5\n",
    "FN_DATE_POS = (-14, -4)\n",
    "FN_DATE_FORMAT = '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778dc4ee-ca30-4fb2-b21f-42dcfd6a2479",
   "metadata": {},
   "source": [
    "### Directories and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_train_file = os.path.join(common.DATASETS_DIR, 'samples_730days.csv')\n",
    "KOPPEN_LEGEND = os.path.join(common.SOURCE_DIR, 'Climate_zones.csv')\n",
    "OUTPUT_FILE = os.path.join(common.MAPS_DIR, 'LFMC_maps', f'{LFMC_SCENARIO}_{DERIVED_MODEL}_{MAP_DATE}.tif')\n",
    "OUTPUT_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_DIR, 'model_params.json'), 'r') as f:\n",
    "    model_params = ModelParams(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bca7be-5191-4cdf-af34-6f0b375b2489",
   "metadata": {},
   "source": [
    "### Load the models\n",
    "Use the \"base\" model and ensemble the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef3ee4-0d67-45f1-82cf-a99850003277",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = ModelList.load_model_set(MODEL_DIR)\n",
    "if isinstance(models, ModelList):\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Loading model {i}\")\n",
    "        model.load_model(DERIVED_MODEL)\n",
    "else:\n",
    "    print(f\"Loading single model\")\n",
    "    models = [models]\n",
    "    models[0].load_model(DERIVED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-allah",
   "metadata": {},
   "source": [
    "## Get Transformation parameters\n",
    "The transformation parameters need to be obtained from the training data, so the mapping data is transformed the same way\n",
    "- Get the normalisation ranges from the MODIS and PRISM data\n",
    "- Get the one-hot encodings from the auxiliary data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5323199f-9280-4143-aba9-c7602c9b6e6f",
   "metadata": {},
   "source": [
    "### Load normalisation bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbcab3-9446-4100-b9a3-c63e3438da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_bounds = load_bounds('modis', MODEL_DIR) #np.genfromtxt(os.path.join(MODEL_DIR, 'modis_bounds.csv'), delimiter=',')\n",
    "prism_bounds = load_bounds('prism', MODEL_DIR) #np.genfromtxt(os.path.join(MODEL_DIR, 'prism_bounds.csv'), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf89b876-d4a6-4faf-83c5-48f1f8002d1b",
   "metadata": {},
   "source": [
    "### Auxiliary One-hot Encoder\n",
    "Create the one-hot encoder and encode the climate zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab6a14-93b8-4752-aa21-2f4267394986",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_params['auxOneHotCols']:\n",
    "    onehot_enc = create_onehot_enc(model_params['auxOneHotCols'], model_dir=MODEL_DIR)\n",
    "    czones = pd.read_csv(KOPPEN_LEGEND, index_col=0)\n",
    "    czones_enc = pd.DataFrame(\n",
    "        onehot_enc.transform(czones[['Code']].to_numpy()),\n",
    "        index=czones.index,\n",
    "        columns=onehot_enc.get_feature_names_out(['Czone']))\n",
    "else:\n",
    "    onehot_enc = None\n",
    "    czones_enc = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a316e36-89fe-4ddc-83a8-6183816af139",
   "metadata": {},
   "source": [
    "### If auxiliary variables are specified by number, get the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4401e3-cd23-47ac-840b-b01f6d11e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model_params['auxColumns'], int):\n",
    "    samples = pd.read_csv(aux_train_file, index_col=0)\n",
    "    model_params['auxColumns'] = list(samples.columns[-model_params['auxColumns']:])\n",
    "    del samples\n",
    "print('Auxiliaries:', model_params['auxColumns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe72b6a8-82fc-42dd-ac38-a96c481aafdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare the mapping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba5022-6834-4862-b9c0-1fae5b94a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_between(date1, date2):\n",
    "    return (datetime.strptime(date2, FN_DATE_FORMAT) - datetime.strptime(date1, FN_DATE_FORMAT)).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41695a7e-d170-430e-9452-73b0a3b25ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_after(fn, date_):\n",
    "    return fn[FN_DATE_POS[0]:FN_DATE_POS[1]] > date_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf7706d-e334-413a-84ca-babe06d296ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_files(file_list, start_date, end_date):\n",
    "    for i, fn in enumerate(file_list):\n",
    "        if file_after(fn, start_date):\n",
    "            break\n",
    "    i = i - 1 if i > 0 else 0\n",
    "    keep_last = True\n",
    "    for j, fn in enumerate(file_list[i:], i):\n",
    "        if file_after(fn, end_date):\n",
    "            keep_last = False\n",
    "            break\n",
    "    j = j + 1 if keep_last else j\n",
    "    return file_list[i:j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec12443-83ae-436f-a6ff-9e97a3aeead4",
   "metadata": {},
   "source": [
    "#### Function to prepare auxiliary data\n",
    "- Reads the auxiliary data into a dataframe with column names set to band descriptions. Adds normalised longitude and latitude (unnormalised values retained for referencing/alignment. Replaces elevation, slope, and aspect with normalized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a820c-6577-44dd-9f78-6c06b8abe6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aux_data(aux_image, bands, offsets, sizes):\n",
    "    aux_data = aux_image.ReadAsArray(xoff=offsets[0], yoff=offsets[1], xsize=sizes[0], ysize=sizes[1]).round(FLOAT_PRE)\n",
    "    aux_data = aux_data.transpose(1, 2, 0).reshape(aux_data.shape[1] * aux_data.shape[2], aux_data.shape[0])\n",
    "    aux_df = pd.DataFrame(aux_data, columns=bands)\n",
    "    aux_df = aux_df.replace(aux_image.GetRasterBand(1).GetNoDataValue(), np.NAN).dropna()\n",
    "    if model_params['auxOneHotCols']:\n",
    "        aux_df = aux_df.merge(czones_enc, left_on='climate_zone', right_index=True)\n",
    "    aux_norm = aux_df.drop(['elevation', 'slope', 'aspect', 'climate_zone'], axis=1)\n",
    "    # doy = datetime.strptime(MAP_DATE, FN_DATE_FORMAT).timetuple().tm_yday\n",
    "    # doy = normalise(doy, method='range', range=(1, 366), out_range=(-np.pi, np.pi))\n",
    "    # aux_norm[\"Day_sin\"] = round(np.sin(doy), FLOAT_PRE)\n",
    "    # aux_norm[\"Day_cos\"] = round(np.cos(doy), FLOAT_PRE)\n",
    "    longitude = normalise(aux_df.longitude, method='range', data_range=(-180, 180), scaled_range=(-np.pi, np.pi))\n",
    "    aux_norm[\"Long_sin\"] = longitude.transform(np.sin).round(FLOAT_PRE)\n",
    "    aux_norm[\"Long_cos\"] = longitude.transform(np.cos).round(FLOAT_PRE)\n",
    "    aux_norm[\"Lat_norm\"] = normalise(aux_df.latitude, method='range', data_range=(-90, 90)).round(FLOAT_PRE)\n",
    "    # aux_norm[\"Elevation\"] = normalise(aux_df.elevation.round(0), method='range', range=(0, 6000)).round(FLOAT_PRE)\n",
    "    # aux_norm[\"Slope\"] = normalise(aux_df.slope.round(0), method='range', range=(0, 90)).round(FLOAT_PRE)\n",
    "    # aspect = normalise(aux_df.aspect.round(0), method='range', range=(0, 360), out_range=(-np.pi, np.pi))\n",
    "    # aux_norm[\"Aspect_sin\"] = aspect.transform(np.sin).round(FLOAT_PRE)\n",
    "    # aux_norm[\"Aspect_cos\"] = aspect.transform(np.cos).round(FLOAT_PRE)\n",
    "    return aux_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe70b5-218c-4f3e-bd01-a9ad782a1b10",
   "metadata": {},
   "source": [
    "#### Function to compute number of pixels between two locations\n",
    "- Input locations can be single values or list-like, but should have the same dimensions\n",
    "- Pixel_size can be a single value, or a value for each pair of location elements\n",
    "- Return value has the same shape as the input locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d092cae-5273-43e0-8a01-94207da8684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_pixels(start_loc, end_loc, pixel_size, convert=np.round):\n",
    "    return_type = type(start_loc)\n",
    "    pixels = (np.array(end_loc) - np.array(start_loc)) / np.array(pixel_size)\n",
    "    if convert:\n",
    "        pixels = convert(pixels)\n",
    "    return return_type(pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c225b312-0341-4201-8697-2b636d6315ce",
   "metadata": {},
   "source": [
    "#### Function to prepare time-series data\n",
    "- Reads data from all images (assumes they are in date order and first image start on ts_start)\n",
    "- Extracts data for the relevant days and pixels\n",
    "  - index parameter indicates required pixels\n",
    "- Interpolates along day axis to fill missing values\n",
    "- Normalises the data using the bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_data(images, offsets, sizes, channels, ts_start, start_date, index, bounds, scaled_range):\n",
    "    ts_data = []\n",
    "    for image in images:\n",
    "        ts_data.append(image.ReadAsArray(xoff=offsets[0], yoff=offsets[1], xsize=sizes[0], ysize=sizes[1]))\n",
    "    start = channels * days_between(ts_start, start_date)\n",
    "    end = start + channels * TS_DAYS\n",
    "    new_shape = (ts_data[0].shape[1] * ts_data[0].shape[2], end - start)\n",
    "    ts_data = np.concatenate(ts_data, axis=0)[start:end].transpose((1, 2, 0)).reshape(new_shape)[index]\n",
    "    ts_data = reshape_data(ts_data, channels)\n",
    "    df = []\n",
    "    for b in range(channels):\n",
    "        df.append(pd.DataFrame(ts_data[:, :, b]).interpolate(axis=1, method=INTERP_METHOD, limit=INTERP_MAXGAP, limit_direction=INTERP_DIRECTION))\n",
    "    ts_data = np.stack(df, axis=-1)\n",
    "    return normalise(ts_data, method='range', data_range=bounds, scaled_range=scaled_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5effb8c3-3d11-44c0-a612-044ffb616c33",
   "metadata": {},
   "source": [
    "#### Function to predict LFMC\n",
    "- Models is a ModelList, with trained model loaded\n",
    "- Returns a series indexed by index parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6ebd0-25c7-4cb9-b407-8d47024a4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, derived_model, x_aux, x_modis, x_prism, index):\n",
    "    preds = []\n",
    "    X = {'modis': x_modis, 'prism': x_prism, 'aux': x_aux}\n",
    "    start_time = time.time()\n",
    "    for num, model in enumerate(models):\n",
    "        preds.append(model.predict(X, derived_model))\n",
    "    pred_time = round(time.time() - start_time, 2)\n",
    "    print(f'Prediction time:', pred_time)\n",
    "    preds = pd.DataFrame(preds, columns=aux_df.index)\n",
    "    return [preds.mean(axis=0), preds.std(axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96877d3-acb6-403c-b2e0-4fcac39c317d",
   "metadata": {},
   "source": [
    "### Create VRTs\n",
    "Mosaic multiple images for the same date into a VRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f188ca-4182-4e49-b856-53d1f5830c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic_images(prefix):\n",
    "    file_list = sorted(glob.glob(prefix + \"*.tif\"))\n",
    "    days = sorted(list({fn[len(prefix) : len(prefix) + (FN_DATE_POS[1] - FN_DATE_POS[0])] for fn in file_list}))\n",
    "    for day in days:\n",
    "        print(prefix, day)\n",
    "        gdal.BuildVRT(prefix + day + \".vrt\", glob.glob(prefix + day + \"*.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa7ab5-fe59-40e5-ad72-803daee86fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GDAL_DATA'] = common.GDAL_DATA\n",
    "os.environ['PROJ_LIB'] = common.PROJ_LIB\n",
    "from osgeo import gdal\n",
    "mosaic_images(os.path.join(common.GEE_MAPS_DIR, IMAGE_DIR, f'MODIS_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b5768e-8235-4ee8-8127-ddd268d24817",
   "metadata": {},
   "source": [
    "### Open Image Files\n",
    "- Allows for multiple MODIS and PRISM images\n",
    "- Assumes MODIS and PRISM image file names include first date in image in file name\n",
    "- Assumes images are contiguous with no overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a8a51-6558-436a-9263-805afd16b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_file = os.path.join(common.GEE_MAPS_DIR, IMAGE_DIR, f'conus_aux.tif')\n",
    "aux_image = gdal.Open(aux_file, gdal.GA_ReadOnly)\n",
    "bands = []\n",
    "for b in range(1, aux_image.RasterCount+1):\n",
    "    bands.append(aux_image.GetRasterBand(b).GetDescription())\n",
    "    \n",
    "end_date = datetime.strptime(MAP_DATE, FN_DATE_FORMAT) - timedelta(TS_OFFSET)\n",
    "start_date = str((end_date - timedelta(TS_DAYS-1)).date())\n",
    "end_date = str(end_date.date())\n",
    "\n",
    "modis_files = sorted(glob.glob(os.path.join(common.GEE_MAPS_DIR, IMAGE_DIR, f'MODIS_*.vrt')))\n",
    "modis_files = select_files(modis_files, start_date, end_date)\n",
    "modis_images = [gdal.Open(fn, gdal.GA_ReadOnly) for fn in modis_files]\n",
    "\n",
    "origin = (modis_images[0].GetGeoTransform()[0], modis_images[0].GetGeoTransform()[3])\n",
    "pixel_size = (modis_images[0].GetGeoTransform()[1], modis_images[0].GetGeoTransform()[5])\n",
    "raster_size = (modis_images[0].RasterXSize, modis_images[0].RasterYSize)\n",
    "origin_aux = num_pixels((aux_image.GetGeoTransform()[0], aux_image.GetGeoTransform()[3]),\n",
    "                        origin, pixel_size)\n",
    "# Process by block - assumes all images and bands have the same block size\n",
    "batch_size = aux_image.GetRasterBand(1).GetBlockSize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df7568f-b4ee-490c-bfa3-c1090b15aabf",
   "metadata": {},
   "source": [
    "#### Convert PRISM data to mapping resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbde08-d658-4070-92ff-0f6d446807ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'prism' in model_params['dataSources']:\n",
    "    prism_files = sorted(glob.glob(os.path.join(common.GEE_MAPS_DIR, IMAGE_DIR, f'PRISM_*.tif')))\n",
    "    prism_files = select_files(prism_files, start_date, end_date)\n",
    "    prism_images = [gdal.Open(fn, gdal.GA_ReadOnly) for fn in prism_files]\n",
    "\n",
    "    # MODIS data projection and resolution\n",
    "    proj = modis_images[0].GetProjection()\n",
    "    geotrans = modis_images[0].GetGeoTransform()\n",
    "    x_size = modis_images[0].RasterXSize\n",
    "    y_size = modis_images[0].RasterYSize\n",
    "\n",
    "    for num in range(len(prism_images)):\n",
    "        # In-memory raster for the reprojected data\n",
    "        print(prism_files[num])\n",
    "        dst = gdal.GetDriverByName('MEM').Create(\"\", x_size, y_size, prism_images[num].RasterCount, gdal.GDT_Float32)\n",
    "        dst.SetGeoTransform(geotrans)\n",
    "        dst.SetProjection(proj)\n",
    "        gdal.ReprojectImage(prism_images[num], dst, proj, proj, gdal.GRA_NearestNeighbour)\n",
    "        prism_images[num] = dst\n",
    "        \n",
    "    origin_prism = num_pixels((prism_images[0].GetGeoTransform()[0], prism_images[0].GetGeoTransform()[3]),\n",
    "                              origin, pixel_size)\n",
    "    print(origin, origin_aux, origin_prism)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed67ca2-94f1-4032-aaba-8d52f60cdaeb",
   "metadata": {},
   "source": [
    "### Create output Geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c48bc45-c101-4dac-a953-e28831ac0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = gdal.GetDriverByName('GTiff')\n",
    "out_map_raster = driver.Create(OUTPUT_FILE, modis_images[0].RasterXSize, modis_images[0].RasterYSize, 2, gdal.GDT_Float32)\n",
    "out_map_raster.SetGeoTransform(modis_images[0].GetGeoTransform())\n",
    "out_map_raster.SetProjection(modis_images[0].GetProjectionRef())\n",
    "lfmc_band = out_map_raster.GetRasterBand(1)\n",
    "lfmc_band.SetNoDataValue(NODATA)\n",
    "std_band = out_map_raster.GetRasterBand(2)\n",
    "std_band.SetNoDataValue(NODATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a6d7a7-96df-4d10-a472-007369208865",
   "metadata": {},
   "source": [
    "## Generate LFMC estimates\n",
    "Loop through the images by raster block, prepare the data, make LFMC predictions and save to output raster.\n",
    "- Nodata pixels are removed before making predictions\n",
    "- Indexes used to link between dataframes and arrays\n",
    "- Block processing skipped if all pixels in aux block are nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced3627-3144-4f27-9000-f2d73ac3e4bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "modis_start = modis_files[0][FN_DATE_POS[0]:FN_DATE_POS[1]]\n",
    "if 'prism' in model_params['dataSources']:\n",
    "    prism_start = prism_files[0][FN_DATE_POS[0]:FN_DATE_POS[1]]\n",
    "augment = model_params['auxAugment']\n",
    "for y_offset in range(0, raster_size[1], batch_size[1]):\n",
    "    for x_offset in range(0, raster_size[0], batch_size[0]):\n",
    "        start_time = time.time()\n",
    "        x_size = min(batch_size[0], raster_size[0] - x_offset)\n",
    "        y_size = min(batch_size[1], raster_size[1] - y_offset)\n",
    "        lfmc_index = pd.Index(range(y_size * x_size))\n",
    "        aux_df = get_aux_data(aux_image, bands, (int(x_offset + origin_aux[0]), int(y_offset + origin_aux[1])), (x_size, y_size))\n",
    "        print(f'Processing block at ({x_offset}, {y_offset}), size ({x_size}, {y_size}), {len(aux_df)} predictions')\n",
    "        if len(aux_df) > 0:\n",
    "            if model_params['auxOneHotCols']:\n",
    "                x_aux = aux_df[model_params['auxColumns'] + list(czones_enc.columns)].to_numpy()\n",
    "            else:\n",
    "                x_aux = aux_df[model_params['auxColumns']].to_numpy()\n",
    "            aux_time = time.time()\n",
    "            print('Aux processing:', round(aux_time - start_time, 2))\n",
    "            x_modis = None\n",
    "            x_prism = None\n",
    "\n",
    "            for source in model_params['dataSources']:\n",
    "                if source == 'modis':\n",
    "                    modis_params = model_params['inputs']['modis']\n",
    "                    x_modis = get_ts_data(\n",
    "                        modis_images,\n",
    "                        (x_offset, y_offset),\n",
    "                        (x_size, y_size),\n",
    "                        modis_params['channels'],\n",
    "                        modis_start,\n",
    "                        start_date,\n",
    "                        aux_df.index,\n",
    "                        modis_bounds,\n",
    "                        modis_params['normalise'].get('scaled_range', (0, 1)),\n",
    "                    )\n",
    "                    if (augment is True) or (isinstance(augment, list) and 'modis' in augment):\n",
    "                        x_aux = np.concatenate([x_aux, x_modis[:, -1, :]], axis=1)\n",
    "                    elif isinstance(augment, dict) and 'modis' in augment.keys():\n",
    "                        offset = augment[input_name] or 1\n",
    "                        x_aux = np.concatenate([x_aux, x_modis[:, -offset, :]], axis=1)\n",
    "                    modis_time = time.time()\n",
    "                    print('Modis processing:', round(modis_time - aux_time, 2))\n",
    "\n",
    "                if source == 'prism':\n",
    "                    prism_params = model_params['inputs']['prism']\n",
    "                    x_prism = get_ts_data(\n",
    "                        prism_images,\n",
    "                        (int(x_offset + origin_prism[0]), int(y_offset + origin_prism[1])),\n",
    "                        (x_size, y_size),\n",
    "                        prism_params['channels'],\n",
    "                        prism_start,\n",
    "                        start_date,\n",
    "                        aux_df.index,\n",
    "                        prism_bounds,\n",
    "                        prism_params['normalise'].get('scaled_range', (0, 1)),\n",
    "                    )\n",
    "                    if (augment is True) or (isinstance(augment, list) and 'prism' in augment):\n",
    "                        x_aux = np.concatenate([x_aux, x_prism[:, -1, :]], axis=1)\n",
    "                    elif isinstance(augment, dict) and 'prism' in augment.keys():\n",
    "                        offset = augment[input_name] or 1\n",
    "                        x_aux = np.concatenate([x_aux, x_prism[:, -offset, :]], axis=1)\n",
    "                    prism_time = time.time()\n",
    "                    print('Prism processing:', round(prism_time - modis_time, 2))\n",
    "\n",
    "            lfmc, std_dev = predict(models, DERIVED_MODEL, x_aux, x_modis, x_prism, aux_df.index)\n",
    "            lfmc = lfmc.reindex(lfmc_index).to_numpy().reshape(1, y_size, x_size)\n",
    "            lfmc[np.isnan(lfmc)] = NODATA\n",
    "            lfmc_band.WriteArray(lfmc[0], xoff=x_offset, yoff=y_offset)\n",
    "            lfmc_band.FlushCache()\n",
    "            std_dev = std_dev.reindex(lfmc_index).to_numpy().reshape(1, y_size, x_size)\n",
    "            std_dev[np.isnan(std_dev)] = NODATA\n",
    "            std_band.WriteArray(std_dev[0], xoff=x_offset, yoff=y_offset)\n",
    "            std_band.FlushCache()\n",
    "        else:\n",
    "            print('No data in block - skipping')\n",
    "            empty = np.full([y_size, x_size], NODATA)\n",
    "            lfmc_band.WriteArray(empty, xoff=x_offset, yoff=y_offset)\n",
    "            lfmc_band.FlushCache()\n",
    "            std_band.WriteArray(empty, xoff=x_offset, yoff=y_offset)\n",
    "            std_band.FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77bb90-d57e-4a8b-bb8a-ccd9ffd7cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del out_map_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e2af6d-3f85-494d-abf1-c92be5dd2afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFMC",
   "language": "python",
   "name": "lfmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
