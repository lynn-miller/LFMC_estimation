{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFMC Projection - Mapping Models\n",
    "Train Nowcasting and 3-month projection models to create LFMC maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import initialise\n",
    "import common\n",
    "from modelling_functions import create_models, run_experiment\n",
    "from architecture_projection import model_params\n",
    "from model_parameters import ExperimentParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories and Input files\n",
    "Change these settings as required\n",
    "- `input_dir`: Directory containing the data extracted from GEE and Globe-LFMC, the outputs from running the `Extract DEM Data.ipynb` and `Extract MODIS Data.ipynb` notebooks.\n",
    "- `modis_csv`: The file containing extracted MODIS data for each sample, created by `Extract MODIS Data.ipynb`\n",
    "- `prism_csv`: The file containing extracted PRISM data for each sample, created by `Extract PRISM Data.ipynb`\n",
    "- `aux_csv`: The file containing extracted sample labels, DEM, climate zone and other auxiliary data, created by `Extract Auxiliary Data.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_csv = os.path.join(common.DATASETS_DIR, 'modis_730days.csv')\n",
    "prism_csv = os.path.join(common.DATASETS_DIR, 'prism_730days.csv')\n",
    "aux_csv = os.path.join(common.DATASETS_DIR, 'samples_730days.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up experiment parameters\n",
    "If the experiment dictionary contains a 'tests' key that is not 'falsy' (False, None, 0, empty list) it is assumed to be a list of tests to run. Each test will run with the specified model parameters. Model parameters not specified will be the same for each test, as set in the main model_params dictionary. A failed run can be restarted by setting the 'restart' key to the test that failed. This test and the remaining tests will then be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment = ExperimentParams({\n",
    "    'name': 'final_models',\n",
    "    'description': 'Nowcasting and 3-month projection models for the LFMC maps',\n",
    "    'tests': [\n",
    "        {'testName': 'Nowcasting',\n",
    "         'inputs': {'optical': {'start': -365, 'end': 0},\n",
    "                    'weather': {'start': -365, 'end': 0}}},\n",
    "        {'testName': '3-months lead time',\n",
    "         'inputs': {'optical': {'start': -275, 'end': 90},\n",
    "                    'weather': {'start': -275, 'end': 90}}},\n",
    "    ],\n",
    "    'restart': None,\n",
    "})\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model parameters\n",
    "Set up and customise the model parameters. Leave all parameters as set here to run Scenario A. To find out more about any parameter, run `model_params.help('<parameter>')` after running this cell to create the ModelParams object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Customize model parameters\n",
    "model_params['modelName'] = experiment['name']\n",
    "model_params['description'] = experiment['description']\n",
    "model_params['samplesFile'] = aux_csv\n",
    "model_params['modelRuns'] = common.ENSEMBLE_SIZE\n",
    "model_params['tempDir'] = common.TEMP_DIR\n",
    "model_params['modelDir'] = os.path.join(common.MODELS_DIR, model_params['modelName'])\n",
    "model_params['derivedModels'] = common.DERIVED_MODELS\n",
    "model_params['seedList'] = [\n",
    "    566, 451, 795, 237, 788, 185, 397, 530, 758, 633,\n",
    "    914, 326, 334, 366, 336, 413, 111, 599, 416, 230,\n",
    "]\n",
    "\n",
    "# Exclude 2018 data from training samples to ensure we don't use any data from the 3-month lead time\n",
    "model_params['yearColumn'] = 'Sampling year'\n",
    "model_params['splitMethod'] = 'byYear'\n",
    "model_params['splitYear'] = 2018\n",
    "\n",
    "model_params['saveModels'] = True\n",
    "model_params['gpuDevice'] = 0\n",
    "\n",
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params.add_input('optical', {'filename': modis_csv, 'channels': 7})\n",
    "model_params.add_input('weather', {'filename': prism_csv, 'channels': 7})\n",
    "model_params['inputs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and run the models\n",
    "Builds and trains the LFMC models.\n",
    "\n",
    "All models, predictions, evaluation statistics, and plots of test results are saved to `model_dir`, with each test and run saved to a separate sub-directory. For each model created, predictions and evaluation statistics are also returned as attributes of the `model` object. These are stored as nested lists, the structure for a full experiment is:\n",
    "- Tests (omitted if not an experiment)\n",
    "  - Runs (omitted for a single run)\n",
    "    - Folds (for k-fold splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = run_experiment(experiment, model_params)\n",
    "for model in models:\n",
    "    display(getattr(model, 'test_stats', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFMC",
   "language": "python",
   "name": "lfmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
